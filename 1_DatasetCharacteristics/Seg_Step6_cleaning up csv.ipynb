{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          filename  top_left_x  top_left_y  bottom_right_x  bottom_right_y\n",
      "0    2388515.0.png         136          89             263             268\n",
      "1    2474327.0.png         153         118             245             238\n",
      "2    2556370.0.png         137          99             262             258\n",
      "3    2660201.0.png         166         142             232             214\n",
      "4    2785016.0.png         134         104             265             252\n",
      "..             ...         ...         ...             ...             ...\n",
      "495  3693466.0.png         131         120             267             236\n",
      "496  3704975.0.png         131         120             267             237\n",
      "497  3709055.0.png         135         124             264             233\n",
      "498  3709895.0.png         170         159             228             197\n",
      "499  3712994.0.png         158         147             241             210\n",
      "\n",
      "[500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def process_csvs_from_folder(folder_path, images_folder):\n",
    "    # Step 1: Find all CSV files in the folder\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    \n",
    "    all_dfs = []  # List to store all dataframes\n",
    "    all_large_tiles = set()  # Set to store all 'large_tile' filenames from CSVs\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        # Step 2: Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Add all 'large_tile' filenames to the set\n",
    "        all_large_tiles.update(df['large_tile'].values)\n",
    "\n",
    "        # Step 3: Filter rows based on the existence of 'large_tile' files in the given images folder\n",
    "        df_filtered = df[df['large_tile'].apply(lambda x: os.path.isfile(os.path.join(images_folder, x)))]\n",
    "\n",
    "        # Add the filtered DataFrame to the list\n",
    "        all_dfs.append(df_filtered)\n",
    "\n",
    "    # Step 4: Concatenate all DataFrames from different CSVs\n",
    "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    # Step 5: Combine 'large_tile' and 'small_tile' into a single 'filename' column\n",
    "    merged_df['filename'] = merged_df['large_tile']  # Use 'large_tile' as the filename column\n",
    "\n",
    "    # Step 6: Drop the original 'large_tile' and 'small_tile' columns\n",
    "    merged_df = merged_df.drop(columns=['large_tile', 'small_tile'])\n",
    "\n",
    "    # Step 7: Reorder columns to make 'filename' the first column\n",
    "    cols = ['filename'] + [col for col in merged_df.columns if col != 'filename']\n",
    "    merged_df = merged_df[cols]\n",
    "\n",
    "    # Step 8: Find missing files in the CSVs (i.e., files in images_folder that are not in all_large_tiles)\n",
    "    all_image_files = {f for f in os.listdir(images_folder) if os.path.isfile(os.path.join(images_folder, f))}\n",
    "    missing_from_csvs = all_image_files - all_large_tiles\n",
    "\n",
    "    # Step 9: Print the missing files (those in images_folder but not in CSVs)\n",
    "    if missing_from_csvs:\n",
    "        print(\"Missing from CSVs (files found in images folder but not in any CSV):\")\n",
    "        for missing_file in missing_from_csvs:\n",
    "            print(missing_file)\n",
    "\n",
    "    return merged_df\n",
    "    \n",
    "# Example usage:\n",
    "folder_path = 'merge_pixel_coordinates_csvs'  # Folder where CSVs are located\n",
    "images_folder = 'seamounts_seg'  # Folder where images are stored\n",
    "\n",
    "result_df = process_csvs_from_folder(folder_path, images_folder)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result_df.to_csv('merged_pixel_coordinates.csv', index=False)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('merged_pixel_coordinates.csv')\n",
    "\n",
    "# Rename the columns\n",
    "df = df.rename(columns={\n",
    "    'filename': 'image_name',\n",
    "    'top_left_x': 'x_min',\n",
    "    'top_left_y': 'y_min',\n",
    "    'bottom_right_x': 'x_max',\n",
    "    'bottom_right_y': 'y_max'\n",
    "})\n",
    "\n",
    "# Overwrite the existing file with the restructured data\n",
    "df.to_csv('merged_pixel_coordinates.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
