{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, so using the methods developed here I was able to download a large dataset of two kinds of images: 1. Shaded relief map tiles of seabed with at least one seamount on it  2. Shaded relief map tiles of seabed without seamounts. With this dataset (that at the moment is 2500 images with seamounts and 1000 without, but could be extended to about 10000 images each) I would like to build a simple neural network with the aim to be able to take on the binary classification task of deciding whether there is a seamount in the image when presented with a new map tile. My first task is to build a baseline model for that, can you assist me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing images...\n",
      "Preprocessing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-11-30 18:00:26.969070: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "image_folder = \"dataset_for_galore_vol_1_1\"  # Root directory of the dataset\n",
    "output_folder = \"temp_processed_images\"  # Temporary folder for cropped images\n",
    "image_size = (128, 128)  # Image dimensions for the model\n",
    "crop_pixels = 70  # Pixels to crop from each border\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "\n",
    "# Categories\n",
    "categories = [\"with_seamount\", \"without_seamount\"]  # Subfolders in `image_folder`\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to crop borders from an image\n",
    "def crop_fixed_border(image, crop_pixels=5):\n",
    "    height, width, _ = image.shape\n",
    "    if height > crop_pixels * 2 and width > crop_pixels * 2:\n",
    "        cropped_image = image[crop_pixels:height-crop_pixels, crop_pixels:width-crop_pixels]\n",
    "        return cropped_image\n",
    "    else:\n",
    "        return image  # Return original image if cropping not possible\n",
    "\n",
    "# Preprocess images (cropping and resizing)\n",
    "print(\"Preprocessing images...\")\n",
    "for category in categories:\n",
    "    category_folder = os.path.join(image_folder, category)\n",
    "    output_category_folder = os.path.join(output_folder, category)\n",
    "    os.makedirs(output_category_folder, exist_ok=True)\n",
    "    \n",
    "    for file_name in os.listdir(category_folder):\n",
    "        image_path = os.path.join(category_folder, file_name)\n",
    "        output_path = os.path.join(output_category_folder, file_name)\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                cropped_image = crop_fixed_border(image, crop_pixels)\n",
    "                resized_image = cv2.resize(cropped_image, image_size)\n",
    "                cv2.imwrite(output_path, resized_image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "print(\"Preprocessing complete.\")\n",
    "\n",
    "# Load processed dataset\n",
    "def load_data(directory, categories):\n",
    "    data, labels = [], []\n",
    "    for label, category in enumerate(categories):\n",
    "        category_folder = os.path.join(directory, category)\n",
    "        for file_name in os.listdir(category_folder):\n",
    "            file_path = os.path.join(category_folder, file_name)\n",
    "            image = cv2.imread(file_path)\n",
    "            if image is not None:\n",
    "                data.append(image)\n",
    "                labels.append(label)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "data, labels = load_data(output_folder, categories)\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Define a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 281ms/step - accuracy: 0.7202 - loss: 0.5055 - val_accuracy: 0.9719 - val_loss: 0.1126\n",
      "Epoch 2/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 273ms/step - accuracy: 0.9534 - loss: 0.1543 - val_accuracy: 0.9794 - val_loss: 0.0725\n",
      "Epoch 3/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 285ms/step - accuracy: 0.9592 - loss: 0.1390 - val_accuracy: 0.9794 - val_loss: 0.0770\n",
      "Epoch 4/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 271ms/step - accuracy: 0.9795 - loss: 0.0886 - val_accuracy: 0.9195 - val_loss: 0.2157\n",
      "Epoch 5/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.9629 - loss: 0.1130 - val_accuracy: 0.9831 - val_loss: 0.0434\n",
      "Epoch 6/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.9783 - loss: 0.0819 - val_accuracy: 0.9569 - val_loss: 0.1083\n",
      "Epoch 7/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 277ms/step - accuracy: 0.9673 - loss: 0.0967 - val_accuracy: 0.9738 - val_loss: 0.0763\n",
      "Epoch 8/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.9773 - loss: 0.0707 - val_accuracy: 0.9850 - val_loss: 0.0458\n",
      "Epoch 9/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.9688 - loss: 0.0882 - val_accuracy: 0.9757 - val_loss: 0.0713\n",
      "Epoch 10/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 273ms/step - accuracy: 0.9660 - loss: 0.0818 - val_accuracy: 0.9888 - val_loss: 0.0515\n",
      "Epoch 11/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.9743 - loss: 0.0636 - val_accuracy: 0.9831 - val_loss: 0.0528\n",
      "Epoch 12/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 269ms/step - accuracy: 0.9756 - loss: 0.0686 - val_accuracy: 0.9831 - val_loss: 0.0667\n",
      "Epoch 13/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 267ms/step - accuracy: 0.9793 - loss: 0.0525 - val_accuracy: 0.9682 - val_loss: 0.0938\n",
      "Epoch 14/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 271ms/step - accuracy: 0.9800 - loss: 0.0606 - val_accuracy: 0.9700 - val_loss: 0.0776\n",
      "Epoch 15/15\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.9766 - loss: 0.0587 - val_accuracy: 0.9850 - val_loss: 0.0511\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9868 - loss: 0.0601\n",
      "Test Loss: 0.057781971991062164, Test Accuracy: 0.9868913888931274\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "   with_seamount       0.99      0.99      0.99       392\n",
      "without_seamount       0.97      0.98      0.98       142\n",
      "\n",
      "        accuracy                           0.99       534\n",
      "       macro avg       0.98      0.98      0.98       534\n",
      "    weighted avg       0.99      0.99      0.99       534\n",
      "\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Classification report\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"seamount_classifier_baseline_with_cropping.h5\")\n",
    "print(\"Model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
