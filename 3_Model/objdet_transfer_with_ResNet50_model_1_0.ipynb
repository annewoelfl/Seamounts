{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA devices:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pixel coord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to your folder containing images\n",
    "image_folder = '../1_DatasetCharacteristics/seamounts_seg_cropped'\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = '../1_DatasetCharacteristics/merged_pixel_coordinates.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Loop through each row in the CSV file\n",
    "for _, row in df.iterrows():\n",
    "    # Get image file name and bounding box coordinates\n",
    "    image_name = row['image_name']\n",
    "    x_min, y_min, x_max, y_max = row['x_min'], row['y_min'], row['x_max'], row['y_max']\n",
    "    \n",
    "    # Load the image\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert image from BGR (OpenCV format) to RGB (matplotlib format)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw the bounding box on the image\n",
    "    cv2.rectangle(image_rgb, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)  # Red bounding box\n",
    "    \n",
    "    # Display the image with the bounding box\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 09:47:23.353065: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-25 09:47:23.360009: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-25 09:47:23.387977: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-25 09:47:23.446180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735120043.685567   27162 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735120043.779215   27162 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-25 09:47:24.090843: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 09:47:32.416967: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Epoch 1/50\n",
      "\u001b[1m 2/13\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.5163 - mae: 0.8963 "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. \n",
      "\u001b[1;31mBitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. \n",
      "\u001b[1;31mKlicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. \n",
      "\u001b[1;31mWeitere Informationen finden Sie unter Jupyter <a href='command:jupyter.viewOutput'>Protokoll</a>."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to data\n",
    "image_dir = \"../1_DatasetCharacteristics/seamounts_seg_cropped\"\n",
    "csv_path = \"../1_DatasetCharacteristics/merged_pixel_coordinates.csv\"\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = (256, 256)  # Resize images to 256x256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "# Load bounding box data\n",
    "bbox_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to load images\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Load in color (BGR format)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Function to preprocess bounding boxes\n",
    "def preprocess_bboxes(row, original_size, resized_size):\n",
    "    x_min, y_min, x_max, y_max = row[['x_min', 'y_min', 'x_max', 'y_max']]\n",
    "    orig_height, orig_width = original_size\n",
    "    resized_height, resized_width = resized_size\n",
    "\n",
    "    # Scale the bounding box coordinates according to the resizing ratio\n",
    "    x_min = x_min * (resized_width / orig_width)\n",
    "    y_min = y_min * (resized_height / orig_height)\n",
    "    x_max = x_max * (resized_width / orig_width)\n",
    "    y_max = y_max * (resized_height / orig_height)\n",
    "\n",
    "    # Normalize coordinates to [0, 1]\n",
    "    x_min /= resized_width\n",
    "    y_min /= resized_height\n",
    "    x_max /= resized_width\n",
    "    y_max /= resized_height\n",
    "\n",
    "    return [x_min, y_min, x_max, y_max]\n",
    "\n",
    "# Prepare dataset\n",
    "images = []\n",
    "bboxes = []\n",
    "for _, row in bbox_data.iterrows():\n",
    "    img_path = os.path.join(image_dir, row['image_name'])\n",
    "    if os.path.exists(img_path):\n",
    "        # Load image without resizing to get original dimensions\n",
    "        original_image = load_image(img_path)\n",
    "        original_size = (original_image.shape[0], original_image.shape[1])\n",
    "\n",
    "        # Preprocess bounding box\n",
    "        bbox = preprocess_bboxes(row, original_size, IMAGE_SIZE)\n",
    "        bboxes.append(bbox)\n",
    "\n",
    "        # Resize the image\n",
    "        resized_image = cv2.resize(original_image, IMAGE_SIZE)\n",
    "        images.append(resized_image)\n",
    "\n",
    "images = np.array(images)\n",
    "bboxes = np.array(bboxes)\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, bboxes, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Huber loss\n",
    "def huber_loss(y_true, y_pred, delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) <= delta\n",
    "    small_error_loss = 0.5 * tf.square(error)\n",
    "    large_error_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(is_small_error, small_error_loss, large_error_loss)\n",
    "\n",
    "# Define the model architecture with transfer learning using ResNet50 as backbone\n",
    "def create_model_with_transfer_learning():\n",
    "    # Load a pre-trained ResNet50 model as the backbone\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "    # Freeze the layers of the base model (optional)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Add custom layers on top for bounding box regression\n",
    "    inputs = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "    x = base_model(inputs, training=False)  # Pass the input through the pre-trained model\n",
    "    x = layers.GlobalAveragePooling2D()(x)  # Global average pooling to reduce dimensions\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)  # Dropout to prevent overfitting\n",
    "    outputs = layers.Dense(4, activation='linear')(x)  # Bounding box output\n",
    "\n",
    "    # Create the final model\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_model_with_transfer_learning()\n",
    "model.compile(optimizer='adam', loss=huber_loss, metrics=['mae'])\n",
    "\n",
    "# Training and validation loss/MAE visualization (Learning curve)\n",
    "def plot_learning_curve(history, start_epoch=5):\n",
    "    # Extract loss and MAE for training and validation data\n",
    "    train_loss = history.history['loss'][start_epoch:]\n",
    "    val_loss = history.history['val_loss'][start_epoch:]\n",
    "    train_mae = history.history['mae'][start_epoch:]\n",
    "    val_mae = history.history['val_mae'][start_epoch:]\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(start_epoch, len(history.history['loss'])), train_loss, label='Train Loss')\n",
    "    plt.plot(range(start_epoch, len(history.history['val_loss'])), val_loss, label='Validation Loss')\n",
    "    plt.title('Loss Curve (after 5 epochs)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(start_epoch, len(history.history['mae'])), train_mae, label='Train MAE')\n",
    "    plt.plot(range(start_epoch, len(history.history['val_mae'])), val_mae, label='Validation MAE')\n",
    "    plt.title('MAE Curve (after 5 epochs)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Mean Absolute Error')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Train the model and get history\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = \"objdet_ResNet50_model.h5\"  # Path where the model will be saved\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Evaluate model performance\n",
    "val_loss, val_mae = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}, Validation MAE: {val_mae}\")\n",
    "\n",
    "# Plot learning curve after training, starting from epoch 5\n",
    "plot_learning_curve(history, start_epoch=5)\n",
    "\n",
    "# Visualize predictions\n",
    "def plot_predictions(images, true_bboxes, pred_bboxes):\n",
    "    for i in range(5):  # Show 5 examples\n",
    "        img = images[i]\n",
    "        true_bbox = true_bboxes[i]\n",
    "        pred_bbox = pred_bboxes[i]\n",
    "\n",
    "        plt.imshow(img)\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        # Plot true bounding box\n",
    "        true_rect = [\n",
    "            true_bbox[0] * w, true_bbox[1] * h,\n",
    "            (true_bbox[2] - true_bbox[0]) * w, (true_bbox[3] - true_bbox[1]) * h\n",
    "        ]\n",
    "        plt.gca().add_patch(plt.Rectangle(\n",
    "            (true_rect[0], true_rect[1]),\n",
    "            true_rect[2], true_rect[3],\n",
    "            edgecolor='green', facecolor='none', lw=2, label='True'\n",
    "        ))\n",
    "\n",
    "        # Plot predicted bounding box\n",
    "        pred_rect = [\n",
    "            pred_bbox[0] * w, pred_bbox[1] * h,\n",
    "            (pred_bbox[2] - pred_bbox[0]) * w, (pred_bbox[3] - pred_bbox[1]) * h\n",
    "        ]\n",
    "        plt.gca().add_patch(plt.Rectangle(\n",
    "            (pred_rect[0], pred_rect[1]),\n",
    "            pred_rect[2], pred_rect[3],\n",
    "            edgecolor='red', facecolor='none', lw=2, label='Predicted'\n",
    "        ))\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Make predictions on the validation set\n",
    "pred_bboxes = model.predict(X_val)\n",
    "\n",
    "# Plot predictions vs true bounding boxes\n",
    "plot_predictions(X_val, y_val, pred_bboxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"try_any_saved_model_with_unseen_data.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
